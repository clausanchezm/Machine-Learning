{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from numpy.random import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Class of k-Nearest Neigbor Classifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class kNN():\n",
    "    def __init__(self, k = 3, exp = 2):\n",
    "    # constructor for kNN classifier \n",
    "    # k is the number of neighbor for local class estimation\n",
    "    # exp is the exponent for the Minkowski distance\n",
    "        self.k = k\n",
    "        self.exp = exp\n",
    "      \n",
    "    def fit(self, X_train, Y_train):\n",
    "    # training k-NN method\n",
    "    # X_train is the training data given with input attributes. n-th row correponds to n-th instance.\n",
    "    # Y_train is the output data (output vector): n-th element of Y_train is the output value for n-th instance in X_train.\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train   \n",
    "         \n",
    "    def getDiscreteClassification(self, X_test):\n",
    "    # predict-class k-NN method\n",
    "    # X_test is the test data given with input attributes. Rows correpond to instances\n",
    "    # Method outputs prediction vector Y_pred_test:  n-th element of Y_pred_test is the prediction for n-th instance in X_test\n",
    "    \n",
    "        Y_pred_test = [] #prediction vector Y_pred_test for all the test instances in X_test is initialized to empty list []\n",
    "\n",
    "   \n",
    "        for i in range(len(X_test)):   #iterate over all instances in X_test\n",
    "            test_instance = X_test.iloc[i] #i-th test instance \n",
    "            \n",
    "            distances = []  #list of distances of the i-th test_instance for all the train_instance s in X_train, initially empty.\n",
    "          \n",
    "            for j in range(len(self.X_train)):  #iterate over all instances in X_train\n",
    "                train_instance = self.X_train.iloc[j] #j-th training instance \n",
    "                distance = self.Minkowski_distance(test_instance, train_instance) #distance between i-th test instance and j-th training instance  \n",
    "                distances.append(distance) #add the distance to the list of distances of the i-th test_instance\n",
    "        \n",
    "            # Store distances in a dataframe. The dataframe has the index of Y_train in order to keep the correspondence with the classes of the training instances \n",
    "            df_dists = pd.DataFrame(data=distances, columns=['dist'], index = self.Y_train.index)\n",
    "        \n",
    "            # Sort distances, and only consider the k closest points in the new dataframe df_knn\n",
    "            df_nn = df_dists.sort_values(by=['dist'], axis=0)\n",
    "            df_knn =  df_nn[:self.k]\n",
    "            \n",
    "            # Note that the index df_knn.index of df_knn contains indices in Y_train of the k-closed training instances to \n",
    "            # the i-th test instance. Thus, the dataframe self.Y_train[df_knn.index] contains the classes of those k-closed \n",
    "            # training instances. Method value_counts() computes the counts (number of occurencies) for each class in \n",
    "            # self.Y_train[df_knn.index] in dataframe predictions. \n",
    "            predictions = self.Y_train[df_knn.index].value_counts()\n",
    "                 \n",
    "            # the first element of the index predictions.index contains the class with the highest count; i.e. the prediction y_pred_test.\n",
    "            y_pred_test = predictions.index[0]\n",
    "\n",
    "            # add the prediction y_pred_test to the prediction vector Y_pred_test for all the test instances in X_test\n",
    "            Y_pred_test.append(y_pred_test)\n",
    "        \n",
    "        return Y_pred_test\n",
    "\n",
    "    \n",
    "    def Minkowski_distance(self, x1, x2):\n",
    "    # computes the Minkowski distance of x1 and x2 for two labeled instances (x1,y1) and (x2,y2)\n",
    "    \n",
    "        # Set initial distance to 0\n",
    "        distance = 0\n",
    "    \n",
    "        # Calculate Minkowski distance using the exponent exp\n",
    "        for i in range(len(x1)):\n",
    "            distance = distance + abs(x1[i] - x2[i])**self.exp\n",
    "        \n",
    "        distance = distance**(1/self.exp)\n",
    "    \n",
    "        return distance\n",
    "    \n",
    "    \n",
    "    def normalize(self, X_train , X_test):\n",
    "        #create new copies of the training sets \n",
    "        trainB = X_train.copy()\n",
    "        testB = X_test.copy()\n",
    "        max_value = X_train.max()\n",
    "        min_value = X_train.min()\n",
    "        \n",
    "        #in order to make sure the normalization is correctly( in case of negative values) , we use the min and max\n",
    "        #extract cols \n",
    "        for col in X_train.columns:\n",
    "            rows = X_train.loc[:,col]\n",
    "            newRows= (rows - min_value[col]).divide(max_value[col] - min_value[col])\n",
    "            trainB.loc[:,col] = newRows\n",
    "       \n",
    "    #clip values to 1 or either 0\n",
    "        for col in X_test.columns: \n",
    "            rows = X_test.loc[:, col]\n",
    "            newRows = (rows - min_value[col]).divide(max_value[col] - min_value[col])\n",
    "            newRows = np.clip(newRows, 0, 1)\n",
    "            testB.loc[:,col] = newRows\n",
    "            \n",
    "            \n",
    "        return testB, trainB \n",
    "    \n",
    "    def getClassProbs(self, X_test, X_train, Y_train) : \n",
    " #posterior prob for each class of data        \n",
    "        posterior_prob = {} #thsi is a dictionary \n",
    "         \n",
    "        for i in range(len(X_test)):   #iterate over all instances in X_test\n",
    "            test_instance = X_test.iloc[i] \n",
    "            \n",
    "            distances = []  #list of distances of the i-th test_instance for all the train_instance s in X_train, initially empty.\n",
    "          \n",
    "            for j in range(len(self.X_train)):  #iterate over all instances in X_train\n",
    "                train_instance = self.X_train.iloc[j] #j-th training instance \n",
    "                distance = self.Minkowski_distance(test_instance, train_instance) #distance between i-th test instance and j-th training instance  \n",
    "                distances.append(distance) #add the distance to the list of distances of the i-th test_instance\n",
    "        \n",
    "            # Store distances in a dataframe. The dataframe has the index of Y_train in order to keep the correspondence with the classes of the training instances \n",
    "            df_dists = pd.DataFrame(data=distances, columns=['dist'], index = self.Y_train.index)\n",
    "        \n",
    "            # Sort distances, and only consider the k closest points in the new dataframe df_knn\n",
    "            df_nn = df_dists.sort_values(by=['dist'], axis=0)\n",
    "            df_knn =  df_nn[:self.k]\n",
    "            \n",
    "            # Note that the index df_knn.index of df_knn contains indices in Y_train of the k-closed training instances to \n",
    "            # the i-th test instance. Thus, the dataframe self.Y_train[df_knn.index] contains the classes of those k-closed \n",
    "            # training instances. Method value_counts() computes the counts (number of occurencies) for each class in \n",
    "            # self.Y_train[df_knn.index] in dataframe predictions. \n",
    "            predictions = Y_train[df_knn.index].value_counts()\n",
    "            \n",
    "            num_of_occurances = self.Y_train[df_knn.index].value_counts()\n",
    "            print(num_of_occurances)\n",
    "           #dictionary that will contain all classes of the neighbours \n",
    "            prob_dic = dict()\n",
    "            \n",
    "            for instance, occurence in num_of_occurances : \n",
    "                probability = occurence / self.k \n",
    "                prob_dict[instance] = probability \n",
    "            posterior_prob[i] = prob_dic\n",
    "            \n",
    "            \n",
    "        return pd.DataFrame(posterior_prob).fillna(0)\n",
    "    \n",
    "    \n",
    "    def getPrediction(self, X_test): \n",
    "        \n",
    "        prob_df = self.getClassProbs(X_test, self.X_train, self.Y_train)\n",
    "        prob_dic = dict()\n",
    "        \n",
    "        #knn regression is done by (1/k) and sum(yi)\n",
    "        for index, price_prob in prob_df.iteritems():\n",
    "            sum_price = 0 \n",
    "             #avg value of k nearest neigh of instance\n",
    "            for price, prob in price_prob.items():\n",
    "                if (prob != 0):\n",
    "                    sum_price += price * prob \n",
    "            prob_dic[index] = sum_price \n",
    "        return pd.DataFrame.from_dict(prob_dic, orient = ' index') \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing for accuracy performance when data is previously normalized andwhen it wasn't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (73, 1), indices imply (141, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9056/938939465.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mY_predTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetDiscreteClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mY_predTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetDiscreteClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mtrainAccNorm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_predTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9056/3469732769.py\u001b[0m in \u001b[0;36mgetDiscreteClassification\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Store distances in a dataframe. The dataframe has the index of Y_train in order to keep the correspondence with the classes of the training instances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mdf_dists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# Sort distances, and only consider the k closest points in the new dataframe df_knn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    709\u001b[0m                     )\n\u001b[0;32m    710\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m                     mgr = ndarray_to_mgr(\n\u001b[0m\u001b[0;32m    712\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"array\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (73, 1), indices imply (141, 1)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.random import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "##################################################\n",
    "# Hold-out testing: Training and Test set creation\n",
    "##################################################\n",
    "\n",
    "data = pd.read_csv('C:/Users/33789/OneDrive/Desktop/Machine Learning/glass.csv')\n",
    "data.head()\n",
    "Y = data['class']\n",
    "X = data.drop(['class'],axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.34, random_state=10)\n",
    "\n",
    "\n",
    "# range for the values of parameter k for kNN\n",
    "\n",
    "k_range = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31]\n",
    "\n",
    "trainAcc = np.zeros(len(k_range))\n",
    "testAcc = np.zeros(len(k_range))\n",
    "index = 0 \n",
    "\n",
    "for k  in  k_range:\n",
    "    clf = kNN(k)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.getDiscreteClassification(X_train)\n",
    "    Y_predTest = clf.getDiscreteClassification(X_test)\n",
    "    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "    \n",
    "   #normalize the data before fitting\n",
    "knn = kNN()\n",
    "X_test, X_train = knn.normalize(X_test, X_train)\n",
    "\n",
    "trainAccNorm = np.zeros(len(k_range))\n",
    "testAccNorm = np.zeros(len(k_range))\n",
    "\n",
    "\n",
    "index = 0 \n",
    "for k  in  k_range:\n",
    "    clf = kNN(k)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.getDiscreteClassification(X_train)\n",
    "    Y_predTest = clf.getDiscreteClassification(X_test)\n",
    "    trainAccNorm[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAccNorm[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "   \n",
    "    \n",
    "#########################################\n",
    "# Plot of training and test accuracies\n",
    "#########################################\n",
    "    \n",
    "plt.plot(k_range,trainAcc,'ro-',k_range,testAcc,'bv--', trainAccNorm, 'g', testAccNorm, 'c')\n",
    "plt.legend(['Training Accuracy','Test Accuracy', 'Norm Train Acc', 'Norm Test Acc'])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the accuracy performance of the kNN classifier throughout the different number of neighbours taken into account to assign a classification to a data instance. As we can see the training accuracy drops as there are more neighbours taken into account, whereas during the test set the accuracy relatively raises and falls as more neighbours are used for classification. \n",
    "The graph shows 4 lines, test set and training set when they are normalized or not. Comparing this set of two lines from the lattest feature, there is an improvement of the normalized data to the non-normalized in small k's approx when k<6, after this both show very similar accuracies. Nevertheless, as we tested before, it is important to recall that the model without any modification worsenst its performance with the more neighbours taken into account, thus there is a degeneracy of accuracy as the number of neighbours considered increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (262, 1), indices imply (506, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9056/1620749078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m#we can only normalize the training data, we can never use before the testing teh test set, Y_train only contains the true class teh instances should be classified thus it is not normalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mY_predTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetDiscreteClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mY_predTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetDiscreteClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mtrainAcc_norm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_predTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9056/3469732769.py\u001b[0m in \u001b[0;36mgetDiscreteClassification\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Store distances in a dataframe. The dataframe has the index of Y_train in order to keep the correspondence with the classes of the training instances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mdf_dists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# Sort distances, and only consider the k closest points in the new dataframe df_knn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    709\u001b[0m                     )\n\u001b[0;32m    710\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m                     mgr = ndarray_to_mgr(\n\u001b[0m\u001b[0;32m    712\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"array\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (262, 1), indices imply (506, 1)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.random import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "##################################################\n",
    "# Hold-out testing: Training and Test set creation\n",
    "##################################################\n",
    "\n",
    "data = pd.read_csv('C:/Users/33789/OneDrive/Desktop/Machine Learning/diabetes.csv')\n",
    "data.head()\n",
    "Y = data['class']\n",
    "X = data.drop(['class'],axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.34, random_state=10)\n",
    "\n",
    "\n",
    "# range for the values of parameter k for kNN\n",
    "\n",
    "k_range = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31]\n",
    "\n",
    "trainAcc = np.zeros(len(k_range))\n",
    "testAcc = np.zeros(len(k_range))\n",
    "trainAcc_norm = np.zeros(len(k_range))\n",
    "testAcc_norm = np.zeros(len(k_range))\n",
    "\n",
    "\n",
    "\n",
    "index = 0 \n",
    "for k  in  k_range:\n",
    "    clf = kNN(k)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.getDiscreteClassification(X_train)\n",
    "    Y_predTest = clf.getDiscreteClassification(X_test)\n",
    "    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "\n",
    "knn = kNN()\n",
    "X_test, X_train = knn.normalize(X_test, X_train)\n",
    "for m in k_range: \n",
    "    clf = kNN(k)\n",
    "    #we can only normalize the training data, we can never use before the testing teh test set, Y_train only contains the true class teh instances should be classified thus it is not normalized \n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.getDiscreteClassification(X_train)\n",
    "    Y_predTest = clf.getDiscreteClassification(X_test)\n",
    "    trainAcc_norm[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc_norm[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "    \n",
    "\n",
    "#########################################\n",
    "# Plot of training and test accuracies\n",
    "#########################################\n",
    "    \n",
    "plt.plot(k_range,trainAcc,'ro-',k_range,testAcc,'bv--', trainAcc_norm, 'g', testAcc_norm, 'c')\n",
    "plt.legend(['Training Accuracy','Test Accuracy', 'Norm Train Acc', 'Norm Test Acc'])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the accuracy performance of training and testing sets when the dat awas normalized and when it wasn't. In contrast to our previous experiment, we cannot see this peak of improvement in accuracy when k is small and the data is normalized. Thus normalizing in this experiment didn't improve our performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we can conclude then that normalization is not always optimal, it depends on the dat we are handiling. In theory it helps brings the same level of importance to all features but in some cases it can result in the misclassifocation of instances, leading accuraries to fall. Nevertheless, our performance variates also with teh number of nearest neighbours taken into account, hence normalization isn't the only thing that can help/worsen efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33789\\AppData\\Local\\Temp/ipykernel_9056/359024825.py:72: RuntimeWarning: overflow encountered in double_scalars\n",
      "  distance = distance + abs(x1[i] - x2[i])**self.exp\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.random import random\n",
    "\n",
    "##################################################\n",
    "# Hold-out testing: Training and Test set creation\n",
    "##################################################\n",
    "\n",
    "data = pd.read_csv('C:/Users/33789/OneDrive/Desktop/Machine Learning/glass.csv')\n",
    "data.head()\n",
    "Y = data['class']\n",
    "X = data.drop(['class'],axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.34, random_state=10)\n",
    "\n",
    "\n",
    "# range for the values of parameter exp for kNN\n",
    "\n",
    "exp_range = [1, 2, 10, 20, 50,  100, 1000]\n",
    "\n",
    "trainAcc = np.zeros(len(k_range))\n",
    "testAcc = np.zeros(len(k_range))\n",
    "trainAcc_norm = np.zeros(len(k_range))\n",
    "testAcc_norm = np.zeros(len(k_range))\n",
    "\n",
    "\n",
    "\n",
    "index = 0 \n",
    "for k  in  k_range:\n",
    "    clf = kNN(k)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.getDiscreteClassification(X_train)\n",
    "    Y_predTest = clf.getDiscreteClassification(X_test)\n",
    "    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "\n",
    "knn = kNN()\n",
    "X_test, X_train = knn.normalize(X_test, X_train)\n",
    "for m in k_range: \n",
    "    clf = kNN(k)\n",
    "    #we can only normalize the training data, we can never use before the testing teh test set, Y_train only contains the true class teh instances should be classified thus it is not normalized \n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.getDiscreteClassification(X_train)\n",
    "    Y_predTest = clf.getDiscreteClassification(X_test)\n",
    "    trainAcc_norm[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc_norm[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "    \n",
    "   \n",
    "    \n",
    "#########################################\n",
    "# Plot of training and test accuracies\n",
    "#########################################\n",
    "    \n",
    "plt.plot(k_range,trainAcc,'ro-',k_range,testAcc,'bv--', trainAcc_norm, 'g', testAcc_norm, 'c')\n",
    "plt.legend(['Training Accuracy','Test Accuracy', 'Norm Train Acc', 'Norm Test Acc'])\n",
    "#use logarithmic scale to make the changes more visible \n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('exp')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph plots the accuracy performance on both data sets with different exponents used in the Minkowski distance. We tested for an interval where the exponent was between 2 and 1000. \n",
    "From this graph we can see there is a slight moment of volatility in accuracy when the exponent is less than 100, and after this point the overall perfomance steadily decreases. \n",
    "Thus I would like to take a closer look when the exp belongs [1, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.random import random\n",
    "\n",
    "##################################################\n",
    "# Hold-out testing: Training and Test set creation\n",
    "##################################################\n",
    "\n",
    "data = pd.read_csv('C:/Users/33789/OneDrive/Desktop/Machine Learning/glass.csv')\n",
    "data.head()\n",
    "Y = data['class']\n",
    "X = data.drop(['class'],axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.34, random_state=10)\n",
    "\n",
    "\n",
    "# range for the values of parameter exp for kNN\n",
    "\n",
    "exp_range = [1, 2, 10, 20, 50,  100]\n",
    "\n",
    "trainAcc = np.zeros(len(k_range))\n",
    "testAcc = np.zeros(len(k_range))\n",
    "trainAcc_norm = np.zeros(len(k_range))\n",
    "testAcc_norm = np.zeros(len(k_range))\n",
    "\n",
    "\n",
    "\n",
    "index = 0 \n",
    "for k  in  k_range:\n",
    "    clf = kNN(k)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.getDiscreteClassification(X_train)\n",
    "    Y_predTest = clf.getDiscreteClassification(X_test)\n",
    "    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "\n",
    "knn = kNN()\n",
    "X_test, X_train = knn.normalize(X_test, X_train)\n",
    "for m in k_range: \n",
    "    clf = kNN(k)\n",
    "    #we can only normalize the training data, we can never use before the testing teh test set, Y_train only contains the true class teh instances should be classified thus it is not normalized \n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.getDiscreteClassification(X_train)\n",
    "    Y_predTest = clf.getDiscreteClassification(X_test)\n",
    "    trainAcc_norm[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc_norm[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "    \n",
    "    \n",
    "#########################################\n",
    "# Plot of training and test accuracies\n",
    "#########################################\n",
    "plt.plot(k_range,trainAcc,'ro-',k_range,testAcc,'bv--', trainAcc_norm, 'g', testAcc_norm, 'c')\n",
    "plt.legend(['Training Accuracy','Test Accuracy', 'Norm Train Acc', 'Norm Test Acc'])\n",
    "#use logarithmic scale to make the changes more visible \n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('exp')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training accuracy we can see that normalized data performs worse than non-normalized. ANd therefore does not improve the accuracy. However, for teh test data the normalized performs better for a small amount of exp, but we must not forget that the sacle is also changed to logarithmic to have a better view of smaller changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n",
      "['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "         preg      plas      pres      skin      insu      mass      pedi  \\\n",
      "659  0.176471  0.402010  0.672131  0.313131  0.082742  0.509687  0.533884   \n",
      "439  0.352941  0.537688  0.721311  0.000000  0.000000  0.548435  0.300413   \n",
      "72   0.764706  0.633166  0.737705  0.000000  0.000000  0.646796  0.240909   \n",
      "329  0.352941  0.527638  0.573770  0.323232  0.080378  0.459016  0.050413   \n",
      "692  0.117647  0.608040  0.573770  0.323232  0.112293  0.582712  0.366116   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "369  0.058824  0.668342  0.836066  0.282828  0.165485  0.488823  0.096694   \n",
      "320  0.235294  0.648241  0.491803  0.121212  0.273050  0.409836  0.217769   \n",
      "527  0.176471  0.582915  0.606557  0.151515  0.124113  0.391952  0.044215   \n",
      "125  0.058824  0.442211  0.245902  0.424242  0.117021  0.819672  0.204959   \n",
      "265  0.294118  0.482412  0.606557  0.181818  0.079196  0.500745  0.411983   \n",
      "\n",
      "          age  \n",
      "659  0.333333  \n",
      "439  0.382716  \n",
      "72   0.518519  \n",
      "329  0.456790  \n",
      "692  0.283951  \n",
      "..        ...  \n",
      "369  0.555556  \n",
      "320  0.382716  \n",
      "527  0.296296  \n",
      "125  0.320988  \n",
      "265  0.530864  \n",
      "\n",
      "[506 rows x 8 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.random import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "##################################################\n",
    "# Hold-out testing: Training and Test set creation\n",
    "##################################################\n",
    "\n",
    "data = pd.read_csv('C:/Users/33789/OneDrive/Desktop/Machine Learning/diabetes.csv')\n",
    "data.head()\n",
    "Y = data['class']\n",
    "X = data.drop(['class'],axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.34, random_state=10)\n",
    "\n",
    "\n",
    "# range for the values of parameter k for kNN\n",
    "\n",
    "k_range = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31]\n",
    "\n",
    "trainAcc = np.zeros(len(k_range))\n",
    "testAcc = np.zeros(len(k_range))\n",
    "\n",
    "\n",
    "index = 0 \n",
    "for k  in  k_range:\n",
    "    clf = kNN(k)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    clf.normalize(X_train)\n",
    "    Y_predTrain = clf.getDiscreteClassification(X_train)\n",
    "    Y_predTest = clf.getDiscreteClassification(X_test)\n",
    "    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "   \n",
    "    \n",
    "#########################################\n",
    "# Plot of training and test accuracies\n",
    "#########################################\n",
    "    \n",
    "plt.plot(k_range,trainAcc,'ro-',k_range,testAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
